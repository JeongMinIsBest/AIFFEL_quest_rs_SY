{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff73528e-b07b-4e04-9778-1322b8ad6804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import urllib.request\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n",
    "\n",
    "import sentencepiece as spm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu, SmoothingFunction\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Matplotlib에서 한글 폰트가 깨지지 않도록 설정합니다.\n",
    "def setup_korean_font():\n",
    "    \"\"\"\n",
    "    Matplotlib에서 한글을 지원하기 위한 폰트 설정을 수행합니다.\n",
    "    나눔 폰트가 없으면 자동으로 다운로드하여 설정합니다.\n",
    "    \"\"\"\n",
    "    font_name = 'NanumGothic'\n",
    "    \n",
    "    # 시스템에 설치된 폰트 확인\n",
    "    if any(font_name in f.name for f in fm.fontManager.ttflist):\n",
    "        print(f\"'{font_name}' 폰트가 이미 설치되어 있습니다.\")\n",
    "        plt.rcParams['font.family'] = font_name\n",
    "    else:\n",
    "        print(f\"'{font_name}' 폰트가 없어 다운로드를 시작합니다.\")\n",
    "        \n",
    "        font_url = 'https://github.com/google/fonts/raw/main/ofl/nanumgothic/NanumGothic-Regular.ttf'\n",
    "        font_path = 'NanumGothic-Regular.ttf'\n",
    "        \n",
    "        try:\n",
    "            # 폰트 파일 다운로드\n",
    "            if not os.path.exists(font_path):\n",
    "                 urllib.request.urlretrieve(font_url, font_path)\n",
    "            \n",
    "            # Matplotlib의 폰트 매니저에 추가\n",
    "            fm.fontManager.addfont(font_path)\n",
    "            \n",
    "            # Matplotlib의 rcParams에 폰트 설정\n",
    "            plt.rcParams['font.family'] = 'NanumGothic'\n",
    "            print(f\"'{font_name}' 폰트 설정이 완료되었습니다.\")\n",
    "        except Exception as e:\n",
    "            print(f\"폰트 다운로드 또는 설정에 실패했습니다: {e}\")\n",
    "            print(\"기본 폰트로 그래프를 생성합니다. 한글이 깨질 수 있습니다.\")\n",
    "            plt.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    print(f\"현재 Matplotlib 폰트: {plt.rcParams['font.family']}\")\n",
    "\n",
    "\n",
    "setup_korean_font()\n",
    "\n",
    "# 1. 데이터 로드 및 전처리\n",
    "print(\"1. 데이터 로드 및 전처리 시작\")\n",
    "try:\n",
    "    df = pd.read_csv(\"ChatbotData.csv\")\n",
    "    print(f\"초기 데이터 개수: {len(df)}\")\n",
    "    \n",
    "    df = df.dropna(subset=[\"Q\", \"A\"])\n",
    "    df = df.drop_duplicates(subset=[\"Q\", \"A\"])\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    questions = df[\"Q\"].values\n",
    "    answers = df[\"A\"].values\n",
    "    \n",
    "    print(f\"전처리 후 데이터 개수: {len(df)}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: ChatbotData.csv 파일을 찾을 수 없습니다.\")\n",
    "    exit()\n",
    "\n",
    "# [수정] 데이터를 8:1:1 비율로 분할\n",
    "# 1차 분할: 훈련+검증 데이터 (90%)와 테스트 데이터 (10%)\n",
    "train_val_questions, test_questions, train_val_answers, test_answers = train_test_split(\n",
    "    questions, answers, test_size=0.1, random_state=42)\n",
    "\n",
    "# 2차 분할: 훈련 데이터 (80%)와 검증 데이터 (10%)\n",
    "# train_val_questions의 1/9을 검증 데이터로 사용 (전체의 10%)\n",
    "train_questions, val_questions, train_answers, val_answers = train_test_split(\n",
    "    train_val_questions, train_val_answers, test_size=1/9, random_state=42)\n",
    "\n",
    "\n",
    "print(f\"\\n훈련 데이터: {len(train_questions)}개, 검증 데이터: {len(val_questions)}개, 테스트 데이터: {len(test_questions)}개\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 2. SentencePiece 토크나이저 훈련 및 로드\n",
    "print(\"\\n2. SentencePiece 토크나이저 훈련 시작\")\n",
    "VOCAB_SIZE = 8000\n",
    "SP_MODEL_PREFIX = 'chatbot_spm'\n",
    "SP_MODEL_PATH = f'{SP_MODEL_PREFIX}.model'\n",
    "SP_CORPUS_PATH = 'chatbot_corpus.txt'\n",
    "\n",
    "# [수정] 훈련(Train) 데이터만으로 토크나이저 학습\n",
    "with open(SP_CORPUS_PATH, 'w', encoding='utf-8') as f:\n",
    "    for q, a in zip(train_questions, train_answers):\n",
    "        f.write(f\"{q}\\n\")\n",
    "        f.write(f\"{a}\\n\")\n",
    "\n",
    "# SentencePiece 모델 훈련\n",
    "spm_command = (f'--input={SP_CORPUS_PATH} --model_prefix={SP_MODEL_PREFIX} '\n",
    "               f'--vocab_size={VOCAB_SIZE} --model_type=bpe '\n",
    "               f'--user_defined_symbols=<pad>,<sos>,<eos>')\n",
    "spm.SentencePieceTrainer.train(spm_command)\n",
    "print(\"SentencePiece 모델 훈련 완료.\")\n",
    "\n",
    "# 훈련된 토크나이저 로드\n",
    "tokenizer = spm.SentencePieceProcessor()\n",
    "tokenizer.load(SP_MODEL_PATH)\n",
    "\n",
    "PAD_IDX = tokenizer.piece_to_id('<pad>')\n",
    "SOS_IDX = tokenizer.piece_to_id('<sos>')\n",
    "EOS_IDX = tokenizer.piece_to_id('<eos>')\n",
    "UNK_IDX = tokenizer.unk_id()\n",
    "\n",
    "print(f\"단어장 크기: {tokenizer.get_piece_size()}\")\n",
    "print(f\"PAD: {PAD_IDX}, SOS: {SOS_IDX}, EOS: {EOS_IDX}, UNK: {UNK_IDX}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 3. 트랜스포머 모델 정의 (어텐션 가중치 반환을 위해 수정)\n",
    "print(\"\\n3. 트랜스포머 모델 정의\")\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# 어텐션 가중치를 반환하도록 Decoder Layer 수정\n",
    "class CustomTransformerDecoderLayer(nn.TransformerDecoderLayer):\n",
    "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None,\n",
    "                tgt_key_padding_mask=None, memory_key_padding_mask=None,\n",
    "                tgt_is_causal=None, memory_is_causal=None):\n",
    "        # Self-Attention\n",
    "        tgt2 = self.self_attn(tgt, tgt, tgt, attn_mask=tgt_mask,\n",
    "                              key_padding_mask=tgt_key_padding_mask)[0]\n",
    "        tgt = tgt + self.dropout1(tgt2)\n",
    "        tgt = self.norm1(tgt)\n",
    "        \n",
    "        # Cross-Attention (Encoder-Decoder Attention)\n",
    "        # 여기서 헤드별 attention weight를 추출하기 위해 average_attn_weights=False 설정\n",
    "        tgt2, attn_weights = self.multihead_attn(tgt, memory, memory, attn_mask=memory_mask,\n",
    "                                                 key_padding_mask=memory_key_padding_mask,\n",
    "                                                 average_attn_weights=False)\n",
    "        tgt = tgt + self.dropout2(tgt2)\n",
    "        tgt = self.norm2(tgt)\n",
    "        \n",
    "        # Feed Forward\n",
    "        tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt))))\n",
    "        tgt = tgt + self.dropout3(tgt2)\n",
    "        tgt = self.norm3(tgt)\n",
    "        return tgt, attn_weights\n",
    "\n",
    "class TransformerChatbot(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout):\n",
    "        super(TransformerChatbot, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "\n",
    "        encoder_layer = TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout, batch_first=True)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layer, num_encoder_layers)\n",
    "        \n",
    "        # 커스텀 디코더 레이어 사용\n",
    "        decoder_layer = CustomTransformerDecoderLayer(d_model, nhead, dim_feedforward, dropout, batch_first=True)\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layer, num_decoder_layers)\n",
    "        \n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, src, tgt, src_padding_mask, tgt_padding_mask, memory_key_padding_mask, tgt_mask):\n",
    "        src_emb = self.pos_encoder(self.embedding(src) * math.sqrt(self.d_model))\n",
    "        tgt_emb = self.pos_encoder(self.embedding(tgt) * math.sqrt(self.d_model))\n",
    "\n",
    "        memory = self.transformer_encoder(src_emb, src_key_padding_mask=src_padding_mask)\n",
    "        \n",
    "        # self.transformer_decoder를 직접 호출하는 대신, 내부 레이어를 수동으로 반복합니다.\n",
    "        # 훈련 시에는 어텐션 가중치가 필요 없으므로, 출력 텐서만 사용합니다.\n",
    "        output = tgt_emb\n",
    "        for mod in self.transformer_decoder.layers:\n",
    "            output, _ = mod(output, memory, \n",
    "                            tgt_mask=tgt_mask,\n",
    "                            tgt_key_padding_mask=tgt_padding_mask,\n",
    "                            memory_key_padding_mask=memory_key_padding_mask)\n",
    "        \n",
    "        return self.fc_out(output)\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz, device):\n",
    "        mask = (torch.triu(torch.ones(sz, sz, device=device)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "print(\"모델 클래스 정의 완료.\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 4. 데이터셋 및 데이터로더\n",
    "print(\"\\n4. 데이터셋 및 데이터로더 생성\")\n",
    "MAX_LEN = 50\n",
    "\n",
    "def text_transform(text, tokenizer):\n",
    "    return torch.tensor([SOS_IDX] + tokenizer.encode_as_ids(text) + [EOS_IDX])\n",
    "\n",
    "class ChatbotDataset(Dataset):\n",
    "    def __init__(self, questions, answers, tokenizer):\n",
    "        self.questions = questions\n",
    "        self.answers = answers\n",
    "        self.tokenizer = tokenizer\n",
    "    def __len__(self): return len(self.questions)\n",
    "    def __getitem__(self, idx):\n",
    "        q_tensor = text_transform(self.questions[idx], self.tokenizer)\n",
    "        a_tensor = text_transform(self.answers[idx], self.tokenizer)\n",
    "        return q_tensor, a_tensor\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(src_sample[:MAX_LEN])\n",
    "        tgt_batch.append(tgt_sample[:MAX_LEN])\n",
    "    src_batch = nn.utils.rnn.pad_sequence(src_batch, padding_value=PAD_IDX, batch_first=True)\n",
    "    tgt_batch = nn.utils.rnn.pad_sequence(tgt_batch, padding_value=PAD_IDX, batch_first=True)\n",
    "    return src_batch, tgt_batch\n",
    "\n",
    "train_dataset = ChatbotDataset(train_questions, train_answers, tokenizer)\n",
    "val_dataset = ChatbotDataset(val_questions, val_answers, tokenizer)\n",
    "test_dataset = ChatbotDataset(test_questions, test_answers, tokenizer)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "print(\"데이터로더 생성 완료.\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 5. 훈련 설정\n",
    "print(\"\\n5. 훈련 설정\")\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"사용 디바이스: {DEVICE}\")\n",
    "\n",
    "D_MODEL = 256\n",
    "N_HEAD = 8\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "D_FF = 512\n",
    "DROPOUT = 0.2\n",
    "LEARNING_RATE = 0.0001\n",
    "EPOCHS = 50\n",
    "\n",
    "model = TransformerChatbot(\n",
    "    VOCAB_SIZE, D_MODEL, N_HEAD, NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, D_FF, DROPOUT\n",
    ").to(DEVICE)\n",
    "\n",
    "def count_parameters(model): return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'모델 파라미터 수: {count_parameters(model):,}')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    loop = tqdm(dataloader, desc=f'Epoch {epoch:02} Train')\n",
    "    for src, tgt in loop:\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        tgt_input = tgt[:, :-1]\n",
    "        tgt_out = tgt[:, 1:]\n",
    "        src_padding_mask = (src == PAD_IDX)\n",
    "        tgt_padding_mask = (tgt_input == PAD_IDX)\n",
    "        tgt_mask = model.generate_square_subsequent_mask(tgt_input.size(1), device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, tgt_input, src_padding_mask, tgt_padding_mask, src_padding_mask, tgt_mask)\n",
    "        loss = criterion(output.reshape(-1, output.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device, epoch):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(dataloader, desc=f'Epoch {epoch:02} Val  ')\n",
    "        for src, tgt in loop:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            tgt_input = tgt[:, :-1]\n",
    "            tgt_out = tgt[:, 1:]\n",
    "            src_padding_mask = (src == PAD_IDX)\n",
    "            tgt_padding_mask = (tgt_input == PAD_IDX)\n",
    "            tgt_mask = model.generate_square_subsequent_mask(tgt_input.size(1), device)\n",
    "            output = model(src, tgt_input, src_padding_mask, tgt_padding_mask, src_padding_mask, tgt_mask)\n",
    "            loss = criterion(output.reshape(-1, output.shape[-1]), tgt_out.reshape(-1))\n",
    "            total_loss += loss.item()\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "print(\"훈련/평가 함수 정의 완료.\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# 6. 훈련 루프\n",
    "print(\"\\n6. 훈련 시작\")\n",
    "best_val_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "patience = 2\n",
    "model_save_path = 'best_transformer_chatbot_sp.pt'\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    start_time = time.time()\n",
    "    train_loss = train_epoch(model, train_dataloader, optimizer, criterion, DEVICE, epoch)\n",
    "    val_loss = evaluate(model, val_dataloader, criterion, DEVICE, epoch)\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = divmod(end_time - start_time, 60)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    print(f'Epoch: {epoch:02} | Time: {int(epoch_mins)}m {int(epoch_secs)}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Val. Loss: {val_loss:.3f}')\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        early_stop_counter = 0\n",
    "        print(\"\\t-> 검증 손실 감소, 모델 저장 완료.\")\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        print(f\"\\t-> 검증 손실 증가. ({early_stop_counter}/{patience})\")\n",
    "    if early_stop_counter >= patience:\n",
    "        print(\"Early stopping. 훈련을 중단합니다.\")\n",
    "        break\n",
    "print(\"\\n훈련 종료.\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 7. 손실 시각화\n",
    "print(\"\\n7. 훈련/검증 손실 시각화\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Epoch별 훈련 및 검증 손실')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(); plt.grid(True)\n",
    "plt.savefig('loss_curve_sp.png')\n",
    "print(\"손실 그래프를 'loss_curve_sp.png' 파일로 저장했습니다.\")\n",
    "plt.show()\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# 8. 모델 로드 및 추론 함수\n",
    "print(\"\\n8. 최적 모델 로드 및 테스트 시작\")\n",
    "model.load_state_dict(torch.load(model_save_path, map_location=DEVICE))\n",
    "\n",
    "def translate_and_get_attention(model, sentence, tokenizer, device):\n",
    "    model.eval()\n",
    "    src_tensor = text_transform(sentence, tokenizer).unsqueeze(0).to(device)\n",
    "    src_padding_mask = (src_tensor == PAD_IDX)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        memory = model.transformer_encoder(model.pos_encoder(model.embedding(src_tensor) * math.sqrt(D_MODEL)), \n",
    "                                           src_key_padding_mask=src_padding_mask)\n",
    "    \n",
    "    ys = torch.ones(1, 1).fill_(SOS_IDX).type(torch.long).to(device)\n",
    "    attentions = []\n",
    "\n",
    "    for i in range(MAX_LEN - 1):\n",
    "        tgt_padding_mask = (ys == PAD_IDX)\n",
    "        tgt_mask = model.generate_square_subsequent_mask(ys.size(1), device)\n",
    "        \n",
    "        tgt_emb = model.pos_encoder(model.embedding(ys) * math.sqrt(D_MODEL))\n",
    "        \n",
    "        output = tgt_emb\n",
    "        temp_attention = None\n",
    "        for layer in model.transformer_decoder.layers:\n",
    "            output, temp_attention = layer(output, memory, tgt_mask=tgt_mask, \n",
    "                                           tgt_key_padding_mask=tgt_padding_mask,\n",
    "                                           memory_key_padding_mask=src_padding_mask)\n",
    "        \n",
    "        # 마지막 레이어, 마지막 토큰의 어텐션 가중치 저장\n",
    "        # temp_attention shape: (batch=1, heads, target_len, source_len)\n",
    "        # 마지막 토큰에 대한 어텐션만 슬라이싱: (heads, source_len)\n",
    "        attentions.append(temp_attention[0, :, -1, :])\n",
    "        \n",
    "        prob = model.fc_out(output[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys, torch.ones(1, 1).type_as(src_tensor.data).fill_(next_word)], dim=1)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "            \n",
    "    generated_tokens = tokenizer.decode(ys.squeeze(0).tolist())\n",
    "    \n",
    "    # 수집된 어텐션들을 target_len 차원을 따라 합침\n",
    "    # attentions: 리스트[ (heads, source_len), (heads, source_len), ... ]\n",
    "    attentions = torch.stack(attentions, dim=1) # -> (heads, target_len, source_len)\n",
    "    \n",
    "    return generated_tokens, attentions\n",
    "\n",
    "\n",
    "# [수정] 예측 결과에서 특수 토큰 제거 후 출력\n",
    "print(\"\\n테스트 데이터 예측 결과 샘플:\")\n",
    "for i in range(5):\n",
    "    q = test_questions[i]\n",
    "    true_a = test_answers[i]\n",
    "    pred_a, _ = translate_and_get_attention(model, q, tokenizer, DEVICE)\n",
    "    \n",
    "    # 특수 토큰 제거\n",
    "    clean_pred_a = pred_a.replace('<sos>', '').replace('<eos>', '').strip()\n",
    "    \n",
    "    print(f\"Q: {q}\")\n",
    "    print(f\"실제 A: {true_a}\")\n",
    "    print(f\"예측 A: {clean_pred_a}\\n\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 9. 실제 어텐션 맵 시각화\n",
    "print(\"\\n9. 실제 어텐션 맵 시각화\")\n",
    "def display_attention(sentence, translation, attention_heads, tokenizer):\n",
    "    sentence_tokens = ['<sos>'] + tokenizer.encode_as_pieces(sentence) + ['<eos>']\n",
    "    \n",
    "    # 예측 결과(translation)는 이미 클리닝되었으므로 그대로 토큰화\n",
    "    translation_pieces = tokenizer.encode_as_pieces(translation)\n",
    "    translation_tokens = ['<sos>'] + translation_pieces + ['<eos>']\n",
    "\n",
    "\n",
    "    # attention: (heads, target_len, source_len)\n",
    "    attention = attention_heads[:, :len(translation_tokens), :len(sentence_tokens)].cpu().detach().numpy()\n",
    "    \n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    for i in range(N_HEAD):\n",
    "        ax = fig.add_subplot(2, 4, i + 1)\n",
    "        cax = ax.matshow(attention[i], cmap='viridis')\n",
    "        ax.set_xticks(range(len(sentence_tokens)))\n",
    "        ax.set_yticks(range(len(translation_tokens)))\n",
    "        ax.set_xticklabels(sentence_tokens, rotation=90, fontsize=8)\n",
    "        ax.set_yticklabels(translation_tokens, fontsize=8)\n",
    "        ax.set_xlabel('Source (Question)'); ax.set_ylabel('Target (Answer)')\n",
    "        ax.set_title(f'Head {i+1}')\n",
    "        \n",
    "    plt.tight_layout(pad=3.0)\n",
    "    plt.savefig('attention_map_sp.png')\n",
    "    print(\"실제 어텐션 맵을 'attention_map_sp.png' 파일로 저장했습니다.\")\n",
    "    plt.show()\n",
    "\n",
    "q_example = test_questions[0]\n",
    "pred_a_example, attention = translate_and_get_attention(model, q_example, tokenizer, DEVICE)\n",
    "\n",
    "# [수정] 시각화할 답변도 특수 토큰 제거\n",
    "clean_pred_a_example = pred_a_example.replace('<sos>', '').replace('<eos>', '').strip()\n",
    "\n",
    "print(f\"시각화할 질문: {q_example}\")\n",
    "print(f\"생성된 답변: {clean_pred_a_example}\")\n",
    "display_attention(q_example, clean_pred_a_example, attention, tokenizer)\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# 10. BLEU 스코어 측정\n",
    "print(\"\\n10. BLEU 스코어 측정\")\n",
    "def calculate_bleu_score(model, dataset, tokenizer, device):\n",
    "    targets = []\n",
    "    predictions = []\n",
    "    smoothing_function = SmoothingFunction().method1\n",
    "\n",
    "    loop = tqdm(zip(dataset.questions, dataset.answers), total=len(dataset.questions), desc=\"Calculating BLEU Score\")\n",
    "    for question, answer in loop:\n",
    "        true_answer_tokens = tokenizer.encode_as_pieces(answer)\n",
    "        predicted_answer, _ = translate_and_get_attention(model, question, tokenizer, device)\n",
    "        \n",
    "        # BLEU 스코어 계산 시에는 특수 토큰을 포함한 원래 토큰 리스트를 사용하는 것이 더 정확할 수 있음\n",
    "        # 여기서는 일관성을 위해 클리닝된 텍스트를 다시 토큰화\n",
    "        clean_predicted_answer = predicted_answer.replace('<sos>', '').replace('<eos>', '').strip()\n",
    "        predicted_answer_tokens = tokenizer.encode_as_pieces(clean_predicted_answer)\n",
    "\n",
    "        targets.append([true_answer_tokens])\n",
    "        predictions.append(predicted_answer_tokens)\n",
    "    \n",
    "    # [수정] sentence_bleu를 corpus_bleu로 변경\n",
    "    corpus_bleu_4 = corpus_bleu(targets, predictions, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothing_function)\n",
    "    corpus_bleu_1 = corpus_bleu(targets, predictions, weights=(1, 0, 0, 0), smoothing_function=smoothing_function)\n",
    "    \n",
    "    return corpus_bleu_1 * 100, corpus_bleu_4 * 100\n",
    "\n",
    "# 작은 샘플로 BLEU 스코어 계산 (전체는 시간이 오래 걸릴 수 있음)\n",
    "sample_test_dataset = ChatbotDataset(test_questions[:100], test_answers[:100], tokenizer)\n",
    "# [수정] 함수 호출 시 빠진 model 인자 추가\n",
    "bleu1, bleu4 = calculate_bleu_score(model, sample_test_dataset, tokenizer, DEVICE)\n",
    "\n",
    "print(f\"테스트 데이터 샘플 100개에 대한 BLEU 스코어:\")\n",
    "print(f\"BLEU-1: {bleu1:.2f}\")\n",
    "print(f\"BLEU-4: {bleu4:.2f}\")\n",
    "print(\"-\" * 30)\n",
    "print(\"\\n모든 작업이 완료되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
